# Parsing
Parsing is basically making sense of a bunch of tokens. For example, if
we were to design a language where you can assign a variable like this:

```
foo = 1
```

We could say that assignment consist of some word, an equals sign, and a number.
The following are _invalid_ assignments:

```
foo = bar # expects a number on the right hand side of the equation
foo       # no equals, no number
foo =     # nothing here!
= foo     # nothing on the left hand side
```

You can see we only accept a small numbers of tokens sequences. In fact, the
accepted sequences must be carefully ordered in order to be valid. A common
solution to this problem, - matching sequences of characters, are regular
expressions. A not-so-common solution is writing a Parser, implementing a
grammar.

Now, let's introduce a little theory. Don't worry, I promise it won't be that
bad.

A _gramar_ is a set of rules which together define all possible character
sequences accepted as valid. They look like this:

```
RuleName := SomeOtherRule A_TERMINAL
```

Rules can consist only of other rules or a terminal. For example, if we wanted
to match a tiny language `L = { 'a', 'b', 'c' }` we could write:

```
Start := 'a'
       | 'b'
       | 'c'
```

Here `'a'`, `'b'` and `'c'` are all terminals. `|` means _or_. We'll also the
_Kleene star_:

    A := 'a'*

Which basically means: Match this 0 or more times, so it will match the empty
string, `a`, `aa`, `aaa` and so on. A very similar one is _Kleen plus_, which
means: Match this 1 or more times.

    B := 'b'+

Will match `b`, `bb`, `bbb` and so on, but not the empty string.

The order in which the grammar tries the rules is not defined theorically, it
just matches all possible variations. For example:

```
Start := 'ab' A
       | 'aba'
A     := 'a'
```

In that grammar, we have two ways of generating 'aba', one is by using the
first branch of the _or_, and the other is using the second brach.

In our imlementation we'll use a top-down approach and just match the first
branch. The second branch would always be ignored in our implementation, so be
careful with those rules.

Languages generated by a grammar are called _formal languages_, you already
know several formal languages I'm sure, some of them are HTML, XML, CSS,
Javascrit, Ruby, Java, C, etc.

Also, we won't write just any grammar, we'll limit our rules in the grammar a
bit, that way we'll only match Context-Free Languages. Why? Because they
represent the best compromise between power of expression and ease of
implementation. [You can learn more about grammars
here](http://www.cs.nuim.ie/~jpower/Courses/Previous/parsing/node21.html).

Which limits will we define? Not much really, we just need to avoid
left-recursion:

```
Foo = Foo "ab"
    | "ab"
```

A rule which calls itself before calling another rule or a terminal. Why this
limitation? Well, one is because it's harder to implement. Because we'll use
functions to implement rules, the implemenation of a left-recursive rule looks
like this:

```ruby
def my_rule
  if my_rule # infinite loop here
    do something
  else
    do something else
  end
end
```

We've got an infinite loop! The good news is that all grammars with
left-recursion [can be written as a different equivalent grammar
without left-recursion](http://www.csd.uwo.ca/~moreno/CS447/Lectures/Syntax.html/node8.html).
In the next section we'll convert a left-recursive grammar into a
non-left-recursive one.

Just one more thing before we move on, I just want to show you how to to
evaluate a grammar _by hand_. Let's this tiny grammar as an example:

```
Assign     = Identifier EQUALS Number
Identifier = WORD
Number     = NUMBER
```

In the grammar above, I want to match an Identifier rule, a token of type EQUALS
(also known as terminal), and a Number. As you can see, we've defined them using
some building blocks called Terminals or Tokens. In our code, we'll tell the
_WORD_ token to match `[a-z]+` and the _NUMBER_ token will match just [0-9].

To try out this grammar, all we need to know is the substitution model. We just
replace rules with their definition until all we have are terminals. Let's say I
want to match `foo = 1`. We must start from the
initial rule and see if we can get to that:

```
Assign = Identifier EQUALS Number
       = WORD EQUALS NUMBER
       = foo EQUALS NUMBER # foo is a valid workd token, we can replace it
       = foo = NUMBER      # = is a valid equals token
       = foo = 1           # 1 is a valid number token
```

Everything looks good! `foo = 1` was generated, so it belongs to our language.

## On Abstract Syntax Trees
Now, just some more theory before I let you go :) The whole point of the grammar
is to get an Abstract Syntax Tree representation - or AST for short, of our
input. For example, a markdown grammar might parse `hello __world__` as:

```
                       [PARAGRAPH]
                           |
                           v
               +-------[SENTENCES] ---------+
               |             |              |
               v             v              v
          [TEXT="hello "] [BOLD="world"] [TEXT="."]
```

> __NOTE__ If you've never seen a tree data structure before, you might [want to
> check that out](https://en.wikipedia.org/wiki/Tree_(data_structure)).

Our parent node is PARAGRAPH. That node has a single child, SENTENCES, which in
turn has 3 children nodes, TEXT, BOLD and another TEXT. The starting rule in our
parser will be the top-most parent in our tree.

The thing about getting a tree out of a grammar is that we can remove ambiguity.
Consider the following grammar:

```
Start    = Binop
Binop    = Binop Operator Binop
         | Number
Operator = + | - | * | /
Number   = 0 | 1 | 2 | ... | 9
```

If we were to manually build an AST for `2 + 2 - 4`, we get

```
                +------[START]--------+
                |         |           |
                v         v           v
             [BINOP] [OPERATOR=-] [NUMBER=4]
                |
   +------------+----------+
   |            |          |
   v            v          v
[NUMBER=2] [OPERATOR=+] [NUMBER=2]
```

So as you can see, we end up matching `(2 + 2) - 4`. The problem, is that an
equally valid representation could be:

```
   +------[START]----------+
   |          |            |
   v          v            v
[NUMBER=2] [OPERATOR=+] [BINOP]
                           |
              +------------+----------|
              |            |          |
              v            v          v
           [NUMBER=2] [OPERATOR=-] [NUMBER=4]
```

So we end up with `2 + (2 - 4)`. We have two possible ASTs to choose from. We
only need one, but we want our programs to be deterministic, and always return
the same AST for the same input. Looks like we'll have to make some choices.

Luckly for us, because we only use non left-recursive grammars, our grammars
don't have ambiguity! Let's see how we would write this as a non left-recursive
grammar:

    Start          = Binop
    Binop          = Substraction
    Substraction   = Adition "-" Binop
    Adition        = Division "+" Binop
    Division       = Multiplication "/" Binop
    Multiplication = Number "*" Binop
    Number         = 0 | 1 | 2 | ... | 9

As you can see, we explicitly set the order of the operations to be performed,
which in this case is Multiplication, Division, Adition, Substraction, like
C. The generated AST will now always be the same.

This method of transforming a left-recursive grammar to a non-left-recursive
grammar works for all cases, so once you've done one, you've done them all. [For
more info on this, you might want to check this
article](http://www.csd.uwo.ca/~moreno/CS447/Lectures/Syntax.html/node8.html).

## A simple Markdown grammar
Okay, enough theory, let's start coding already! This is the grammar we'll
implement:

    Body               := Paragraph*

    Paragraph          := SentenceAndNewline
                        | SentenceAndEOF

    SentenceAndNewline := Sentence+ NEWLINE NEWLINE

    SentencesAndEOF    := Sentence+ NEWLINE EOF
                        | Sentence+ EOF

    Sentence           := EmphasizedText
                        | BoldText
                        | Text

    EmphasizedText     := UNDERSCORE BoldText UNDERSCORE

    BoldText           := UNDERSCORE UNDERSCORE TEXT UNDERSCORE UNDERSCORE
                        | STAR STAR TEXT STAR STAR

    Text               := TEXT

Note that the `Text` rule seems quite silly. It's just so it makes the
implementation easier, we could easily get rid of it and just replace it with
`TEXT`.

Our starting rule is Body, which just matches 0 or more Paragraphs. Each
paragraph is made of either a `SentenceAndNewline` rule or a `SentenceAndEOF`
rule. A Sentence is just text, bold text, or emphasized text.

## Implementation
The approach we'll take is creating an object for each rule in the parser. That
rule might as well call other objects, including itself.

For example, the `TEXT` parser matches a single `TEXT` token. 

```
class TextParser < BaseParser
  def match(tokens)
    return Node.null unless tokens.peek('TEXT')
    Node.new(type: 'TEXT', value: tokens.first.value, consumed: 1)
  end
end
```

You can see we return a null node if we could not match something, otherwise,
we return a valid node. We call the result _node_ because we want to build an
abstract syntax tree.

Let's see a parser a bit more complicated, `__bold__ **text**`:

```
class BoldParser < BaseParser
  def match(tokens)
    return Node.null unless tokens.peek_or(%w(UNDERSCORE UNDERSCORE TEXT UNDERSCORE UNDERSCORE), %w(STAR STAR TEXT STAR STAR))
    Node.new(type: 'BOLD', value: tokens.third.value, consumed: 5)
  end
end
```

Once again, we just check the token sequence is valid and return a node. The 
`peek_or` method takes some arrays as arguments and tries those tokens one by
one. It stops whenever it finds a match, returning true. 

The emphasis parser is quite similar to this one, so let's move onto something
more interesting: The sentence parser. Our rule is `Sentence :=
EmphasizedText | BoldText | Text`. Seems simple enough, `match_first` does the
trick fos us:

```
class SentenceParser < BaseParser
  def match(tokens)
    match_first tokens, emphasis_parser, bold_parser, text_parser
  end
end
```

It will try the given parsers and return the first valid node it finds. The
order of the parsers is very important as they get tested in the given order.

Now, onto the next rule: `SentenceAndNewline := Sentence+ NEWLINE NEWLINE`.

```ruby
class SentencesAndNewlineParser < BaseParser
  include MatchesStar

  def match(tokens)
    nodes, consumed = match_star tokens, with: sentence_parser
    return Node.null if nodes.empty?
    return Node.null unless tokens.peek_at(consumed, 'NEWLINE', 'NEWLINE')
    consumed += 2 # consume newlines

    SentenceNode.new(sentences: nodes, consumed: consumed)
  end
end
```

Similar to `match_one`, we now have another helper, `match_star`, which matches
something 0 or more times. Because we are matching a `+`, we actually want to
mach something once or more, so we error if we got nothing from our `match_star`
method. Then we just match the two `NEWLINE` and return the node.

Our little helpers take away most of the job, as the remaining parsers are
quite trivial. For example, this is our `Body` parser:

    class BodyParser < BaseParser
      include MatchesStar

      def match(tokens)
        nodes, consumed = match_star tokens, with: paragraph_parser
        return Node.null if nodes.empty?
        BodyNode.new(paragraphs: nodes, consumed: consumed)
      end
    end

Now what's missing is something to start calling up parsers, a simple `Parser`
object which abstracts away all these stuff:

    class Parser
      def parse(tokens)
        body = body_parser.match(tokens)
        raise "Syntax error: #{tokens[body.consumed]}" unless tokens.count == body.consumed
        body
      end

      private

      def body_parser
        @body_parser ||= ParserFactory.build(:body_parser)
      end
    end

# That's it!
We've made it a long way so far. We can now transform 
`__Foo__ and *bar*.\n\nAnother paragraph.` into a tree data structure:

    => #<BodyNode:0x007fc774abe008
     @consumed=14,
     @paragraphs=
      [#<SentenceNode:0x007fc774eb25d8
        @consumed=12,
        @sentences=
         [#<Node:0x007fc774ea8150 @consumed=5, @type="BOLD", @value="Foo">,
          #<Node:0x007fc774ac5f60 @consumed=1, @type="TEXT", @value=" and ">,
          #<Node:0x007fc774ac6758 @consumed=3, @type="EMPHASIS", @value="bar">,
          #<Node:0x007fc774eb33e8 @consumed=1, @type="TEXT", @value=".">]>,
       #<SentenceNode:0x007fc774eb0828 @consumed=2, @sentences=[#<Node:0x007fc774eb1610 @consumed=1, @type="TEXT", @value="Another paragraph.">]>]>

And that is no easy feat! We've talked a lot about parsers, grammars, tokens and
all that stuff. More than enough to sip in for a day. Next time, we'll look at
the final part of our compiler: The code generation layer. Hope you find this
useful, and see you there!
